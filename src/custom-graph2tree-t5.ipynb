{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWUMJU6VtSop"
   },
   "source": [
    "# Installation\n",
    "\n",
    "Use Conda and Pip to help us install packages for this homework. If you do not have Miniconda or Anaconda, you can install Miniconda from here https://docs.conda.io/en/latest/miniconda.html.\n",
    "\n",
    "```\n",
    "conda create --name competition python=3.7\n",
    "conda activate competition\n",
    "\n",
    "pip install jupyter pandas\n",
    "```\n",
    "\n",
    "Go to https://pytorch.org/ to install PyTorch if you don't have it already\n",
    "\n",
    "To install the Hugging Face `transformers` library, run\n",
    "```\n",
    "pip install transformers\n",
    "```\n",
    "\n",
    "Follow the instructions from https://docs.dgl.ai/en/0.4.x/install/ to install Deep Graph Library (DGL).\n",
    "\n",
    "Spin up jupyter notebook with\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "Implementation of [Graph-to-Tree Learning for Solving Math Word Problems] https://www.aclweb.org/anthology/2020.acl-main.362.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8er3KIGuRCI"
   },
   "outputs": [],
   "source": [
    "# ! pip install transformers\n",
    "# ! pip install dgl-cu101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e7Q4nluxaw4"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a744bRaXxh14"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZn9VN0ctSoq"
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import itertools\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import GraphConv\n",
    "\n",
    "#from utils import setup, check_match, sub_nP, evaluate_prefix_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X-Q0L7HD0jQN"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmxBbF3dtSou"
   },
   "source": [
    "# Converting Inputs to Torch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_hBspcLtSou"
   },
   "outputs": [],
   "source": [
    "def tensorize_data(data):\n",
    "    for d in data:\n",
    "        ## We already have the indices of the tokens\n",
    "        ##d['in_idxs'] = torch.tensor([in_vocab.token2idx.get(x, in_vocab.unk) for x in d['in_tokens']])\n",
    "        d['in_idxs'] = d['question']\n",
    "        d['n_in'] = n_in = len(d['in_idxs'][0])\n",
    "        d['n_nP'] = n_nP = len(d['nP'][0])\n",
    "        ##d['nP_in_mask'] = mask = torch.zeros(n_in, dtype=torch.bool)\n",
    "        ##mask[d['nP_positions']] = True\n",
    "        ##d['nP_in_mask'] = d['nP_positions']\n",
    "        if 'out_tokens' in d:\n",
    "            d['out_idxs'] = torch.tensor([out_vocab.token2idx.get(x, out_vocab.unk) for x in d['out_tokens']])\n",
    "            d['n_out'] = len(d['out_idxs'])\n",
    "            d['nP_out_mask'] = mask = torch.zeros(n_max_nP, dtype=torch.bool)\n",
    "            mask[:n_nP] = True\n",
    "        d['qcomp_edges'] = get_quantity_comparison_edges(d)\n",
    "        d['qcell_edges'] = get_quantity_cell_edges(d)\n",
    "\n",
    "def get_quantity_comparison_edges(d):\n",
    "    #print(d['nP'][0])\n",
    "    quants = [float(x) for x in d['nP'][0]]\n",
    "    quant_positions = d['nP_positions'][0]\n",
    "    #print(quant_positions, d['n_in'])\n",
    "    assert max(quant_positions) < d['n_in']\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=np.bool)\n",
    "    for x, x_pos in zip(quants, quant_positions):\n",
    "        for y, y_pos in zip(quants, quant_positions):\n",
    "            adj_matrix[x_pos, y_pos] |= x > y\n",
    "    src_ids, dst_ids  = np.transpose(np.nonzero(adj_matrix))\n",
    "    return (src_ids, dst_ids)\n",
    "\n",
    "def get_quantity_cell_edges(d):\n",
    "    in_idxs = d['in_idxs'][0]\n",
    "    quant_positions = d['nP_positions'][0]\n",
    "    quant_cell_positions = d['quant_cell_positions']\n",
    "    assert max(quant_cell_positions) < d['n_in']\n",
    "    word_cells = set(quant_cell_positions) - set(quant_positions)\n",
    "    adj_matrix = torch.eye(d['n_in'], dtype=torch.bool)\n",
    "    for w_pos in word_cells:\n",
    "        for q_pos in quant_positions:\n",
    "            if abs(w_pos - q_pos) < 4:\n",
    "                adj_matrix[w_pos, q_pos] = adj_matrix[q_pos, w_pos] = True\n",
    "    pos_idxs = in_idxs[quant_cell_positions]\n",
    "    for idx1, pos1 in zip(pos_idxs, quant_cell_positions):\n",
    "        for idx2, pos2 in zip(pos_idxs, quant_cell_positions):\n",
    "            if idx1 == idx2:\n",
    "                adj_matrix[pos1, pos2] = adj_matrix[pos2, pos1] = True\n",
    "    src_ids, dst_ids  = np.transpose(np.nonzero(adj_matrix))\n",
    "    return (src_ids, dst_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkofME2dtSox"
   },
   "outputs": [],
   "source": [
    "class TransformerAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qkv = nn.Linear(n_hid, n_head * (n_k * 2 + n_v))\n",
    "        self.out = nn.Linear(n_head * n_v, n_hid)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        n_batch, n_batch_max_in, n_hid = x.shape\n",
    "        q_k_v = self.qkv(x).view(n_batch, n_batch_max_in, n_head, 2 * n_k + n_v).transpose(1, 2)\n",
    "        q, k, v = q_k_v.split([n_k, n_k, n_v], dim=-1)\n",
    "\n",
    "        q = q.reshape(n_batch * n_head, n_batch_max_in, n_k)\n",
    "        k = k.reshape_as(q).transpose(1, 2)\n",
    "        qk = q.bmm(k) / np.sqrt(n_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            qk = qk.view(n_batch, n_head, n_batch_max_in, n_batch_max_in).transpose(1, 2)\n",
    "            qk[~mask] = -np.inf\n",
    "            qk = qk.transpose(1, 2).view(n_batch * n_head, n_batch_max_in, n_batch_max_in)\n",
    "        qk = qk.softmax(dim=-1)\n",
    "        v = v.reshape(n_batch * n_head, n_batch_max_in, n_v)\n",
    "        qkv = qk.bmm(v).view(n_batch, n_head, n_batch_max_in, n_v).transpose(1, 2).reshape(n_batch, n_batch_max_in, n_head * n_v)\n",
    "        out = self.out(qkv)\n",
    "        return x + out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.attn = TransformerAttention()\n",
    "        n_inner = n_hid * 4\n",
    "        self.inner = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_inner),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(n_inner, n_hid)\n",
    "        )\n",
    "    def forward(self, x, mask=None):\n",
    "        x = x + self.attn(x, mask=mask)\n",
    "        return x + self.inner(x)\n",
    "    \n",
    "class GCNBranch(nn.Module):\n",
    "    def __init__(self, n_hid_in, n_hid_out, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.gc1 = dgl.nn.GraphConv(n_hid_in, n_hid_in, allow_zero_in_degree=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.gc2 = dgl.nn.GraphConv(n_hid_in, n_hid_out, allow_zero_in_degree=True) \n",
    "    def forward(self, x, graph):\n",
    "        out = self.gc1(graph, x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.gc2(graph, out)\n",
    "        return out\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_head=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.branches = nn.ModuleList(GCNBranch(n_hid, n_hid // n_head, dropout) for _ in range(n_head))\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(n_hid, n_hid),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(n_hid, n_hid),\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(n_hid)\n",
    "\n",
    "    def forward(self, h, gt_graph, attr_graph):\n",
    "        x = h.reshape(-1, n_hid)\n",
    "        graphs = [gt_graph, gt_graph, attr_graph, attr_graph]\n",
    "        x = torch.cat([branch(x, g) for branch, g in zip(self.branches, graphs)], dim=-1).view_as(h)\n",
    "        x = h + self.layer_norm(x)\n",
    "        return x + self.feed_forward(x)\n",
    "\n",
    "\n",
    "class GraphAttentionLayer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        self.a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, h, adj):\n",
    "        Wh = torch.mm(h, self.W)\n",
    "        a_input = self._prepare_attentional_mechanism_input(Wh)\n",
    "        e = self.leakyrelu(torch.matmul(a_input, self.a).squeeze(2))\n",
    "\n",
    "        zero_vec = -9e15*torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, zero_vec)\n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime = torch.matmul(attention, Wh)\n",
    "\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime\n",
    "\n",
    "    def _prepare_attentional_mechanism_input(self, Wh):\n",
    "        N = Wh.size()[0]\n",
    "        Wh_repeated_in_chunks = Wh.repeat_interleave(N, dim=0)\n",
    "        Wh_repeated_alternating = Wh.repeat(N, 1)\n",
    "        all_combinations_matrix = torch.cat([Wh_repeated_in_chunks, Wh_repeated_alternating], dim=1)\n",
    "        return all_combinations_matrix.view(N, N, 2 * self.out_features)\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
    "        for i, attention in enumerate(self.attentions):\n",
    "            self.add_module('attention_{}'.format(i), attention)\n",
    "\n",
    "        self.out_att = GraphAttentionLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = F.elu(self.out_att(x, adj))\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class Gate(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super(Gate, self).__init__()\n",
    "        self.t = nn.Linear(n_in, n_out)\n",
    "        self.s = nn.Linear(n_in, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.t(x).tanh() * self.s(x).sigmoid()\n",
    "\n",
    "class TreeDecoder(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "        self.constant_embedding = nn.Parameter(torch.randn(1, out_vocab.n_constants, n_hid))\n",
    "\n",
    "        self.qp_gate = nn.Sequential(drop, Gate(n_hid, n_hid))\n",
    "        self.gts_right = nn.Sequential(drop, Gate(2 * n_hid, n_hid))\n",
    "\n",
    "        self.attn_fc = nn.Sequential(drop,\n",
    "            nn.Linear(2 * n_hid, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1)\n",
    "        )\n",
    "        self.quant_fc = nn.Sequential(drop,\n",
    "            nn.Linear(n_hid * 3, n_hid),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hid, 1, bias=False)\n",
    "        )\n",
    "        self.op_fc = nn.Sequential(drop, nn.Linear(n_hid * 2, out_vocab.n_ops))\n",
    "\n",
    "        self.op_embedding = nn.Embedding(out_vocab.n_ops + 1, n_hid, padding_idx=out_vocab.n_ops)\n",
    "        self.gts_left = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "        self.gts_left_qp = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid), self.qp_gate)\n",
    "\n",
    "        self.subtree_gate = nn.Sequential(drop, Gate(n_hid * 2 + n_hid, n_hid))\n",
    "\n",
    "    def gts_attention(self, q, zbar, in_mask=None):\n",
    "        attn_score = self.attn_fc(\n",
    "            torch.cat([q.unsqueeze(1).expand_as(zbar), zbar], dim=2)\n",
    "        ).squeeze(2)\n",
    "        if in_mask is not None:\n",
    "            attn_score[~in_mask] = -np.inf\n",
    "        attn = attn_score.softmax(dim=1)\n",
    "        return (attn.unsqueeze(1) @ zbar).squeeze(1) # (n_batch, n_hid)\n",
    "\n",
    "    def gts_predict(self, qp_Gc, quant_embed, nP_out_mask=None):\n",
    "        quant_score = self.quant_fc(\n",
    "            torch.cat([qp_Gc.unsqueeze(1).expand(-1, quant_embed.size(1), -1), quant_embed], dim=2)\n",
    "        ).squeeze(2)\n",
    "        op_score = self.op_fc(qp_Gc)\n",
    "        pred_score = torch.cat((op_score, quant_score), dim=1)\n",
    "        if nP_out_mask is not None:\n",
    "            pred_score[:, out_vocab.base_nP:][~nP_out_mask] = -np.inf\n",
    "        return pred_score\n",
    "\n",
    "    def merge_subtree(self, op, tl, yr):\n",
    "        return self.subtree_gate(torch.cat((op, tl, yr), dim=-1))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        drop = nn.Dropout(dropout)\n",
    "\n",
    "        if use_t5:\n",
    "            self.t5_encoder = t5_model.encoder        \n",
    "            for i_layer, block in enumerate(self.t5_encoder.block):\n",
    "                if i_layer in freeze_layers:\n",
    "                    for param in block.parameters():\n",
    "                        param.requires_grad = False\n",
    "        else:\n",
    "            self.in_embed = nn.Sequential(nn.Embedding(in_vocab.n, n_hid, padding_idx=in_vocab.pad), drop)\n",
    "            self.pos_embed = nn.Embedding(1 + n_max_in, n_hid)\n",
    "            self.transformer_layers = nn.ModuleList(TransformerBlock() for _ in range(n_layers))\n",
    "\n",
    "        self.gcn = GCN()\n",
    "\n",
    "        self.decoder = TreeDecoder()\n",
    "\n",
    "        if not use_t5:\n",
    "            self.apply(self.init_weight)\n",
    "\n",
    "    def init_weight(self, m):\n",
    "        if type(m) in [nn.Embedding]:\n",
    "            nn.init.normal_(m.weight, 0, 0.1)\n",
    "\n",
    "    def encode(self, in_idxs, n_in, gt_graph, attr_graph, in_mask=None):\n",
    "        in_idxs_pad = F.pad(in_idxs, (1, 0), value=in_vocab.pad)\n",
    "        if use_t5:\n",
    "            \"\"\"\n",
    "            Use your T5 encoder to encoder the input indices. Note that you do NOT need to use an input embedding or\n",
    "            positional embedding (e.g. self.in_embed or self.pos_embed) for T5, since it already defines\n",
    "            the embeddings internally\n",
    "            \"\"\"\n",
    "            h, = self.t5_encoder(in_idxs_pad)\n",
    "        else:\n",
    "            x = self.in_embed(in_idxs_pad)\n",
    "            h = x + self.pos_embed(torch.arange(x.size(1), device=x.device))\n",
    "            for layer in self.transformer_layers:\n",
    "                h = layer(h, mask=in_mask)\n",
    "        zg, h = h[:, 0], h[:, 1:]\n",
    "        zbar = self.gcn(h, gt_graph, attr_graph)\n",
    "        return zbar, zg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-TA9bR2ltSoz"
   },
   "source": [
    "# Training a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp2Yf0qttSo0"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Node for tree traversal during training\n",
    "    \"\"\"\n",
    "    def __init__(self, up):\n",
    "        self.up = up\n",
    "        self.is_root = up is None\n",
    "        self.left = self.right = None\n",
    "        self.ql = self.tl = self.op = None\n",
    "\n",
    "def train(batch, model, opt):\n",
    "    n_batch = len(batch)\n",
    "\n",
    "    n_in = [d['n_in'] for d in batch]\n",
    "    pad = lambda x, value: nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value=value)\n",
    "    in_idxs = pad([d['in_idxs'] for d in batch], in_vocab.pad).to(device)\n",
    "    in_mask = pad([torch.ones(n, dtype=torch.bool) for n in n_in], False).to(device)\n",
    "    nP_in_mask = pad([d['nP_in_mask'] for d in batch], False).to(device)\n",
    "    nP_out_mask = torch.stack([d['nP_out_mask'] for d in batch]).to(device)\n",
    "    \n",
    "    n_nodes = max([len(d['in_tokens']) for d in batch])\n",
    "    qcomp_graph, qcell_graph = [], []\n",
    "    for d in batch:\n",
    "        qcomp_graph_i = dgl.graph(get_quantity_comparison_edges(d), num_nodes=n_nodes).to(device)\n",
    "        qcell_graph_i = dgl.graph(get_quantity_cell_edges(d), num_nodes=n_nodes).to(device)\n",
    "        \n",
    "        qcomp_graph.append(qcomp_graph_i)\n",
    "        qcell_graph.append(qcell_graph_i)\n",
    "    qcomp_graph = dgl.batch(qcomp_graph)\n",
    "    qcell_graph = dgl.batch(qcell_graph)\n",
    "    \n",
    "    label = pad([d['out_idxs'] for d in batch], out_vocab.pad)\n",
    "    nP_candidates = [d['nP_candidates'] for d in batch]\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, n_in, qcomp_graph, qcell_graph, in_mask=None)\n",
    "    z_nP = zbar.new_zeros((n_batch, n_max_nP, n_hid))\n",
    "    z_nP[nP_out_mask] = zbar[nP_in_mask]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    n_quant = out_vocab.n_constants + n_max_nP\n",
    "    quant_embed = torch.cat([decoder.constant_embedding.expand(n_batch, -1, -1), z_nP], dim=1)\n",
    "\n",
    "    nodes = np.array([Node(None) for _ in range(n_batch)])\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "    quant_min, quant_max = out_vocab.base_quant, out_vocab.base_quant + n_quant\n",
    "\n",
    "    qp = decoder.qp_gate(qroot)\n",
    "    scores = []\n",
    "    for i, label_i in enumerate(label.T): \n",
    "        Gc = decoder.gts_attention(qp, zbar, in_mask)\n",
    "        qp_Gc = torch.cat([qp, Gc], dim=1)\n",
    "\n",
    "        score = decoder.gts_predict(qp_Gc, quant_embed, nP_out_mask)\n",
    "        scores.append(score)\n",
    "\n",
    "        is_op = (op_min <= label_i) & (label_i < op_max)\n",
    "        is_quant = ((quant_min <= label_i) & (label_i < quant_max)) | (label_i == out_vocab.unk)\n",
    "\n",
    "        op_embed = decoder.op_embedding((label_i[is_op] - out_vocab.base_op).to(device))\n",
    "        qp_Gc_op = torch.cat([qp_Gc[is_op], op_embed], dim=1)\n",
    "\n",
    "        is_left = np.zeros(n_batch, dtype=np.bool)\n",
    "        qleft_qp = decoder.gts_left_qp(qp_Gc_op)\n",
    "        qleft = decoder.gts_left(qp_Gc_op)\n",
    "        for j, ql, op in zip(is_op.nonzero(as_tuple=True)[0], qleft, op_embed):\n",
    "            node = nodes[j]\n",
    "            nodes[j] = node.left = Node(node)\n",
    "            node.op = op\n",
    "            node.ql = ql\n",
    "            is_left[j] = True\n",
    "\n",
    "        is_right = np.zeros(n_batch, dtype=np.bool)\n",
    "        nP_score = score[:, out_vocab.base_nP:].detach().cpu()\n",
    "        ql_tl = []\n",
    "        for j in is_quant.nonzero(as_tuple=True)[0]:\n",
    "            if label_i[j] == out_vocab.unk:\n",
    "                candidates = nP_candidates[j][i]\n",
    "                label_i[j] = out_vocab.base_nP + candidates[nP_score[j, candidates].argmax()]\n",
    "\n",
    "            node = nodes[j]\n",
    "            pnode = node.up\n",
    "            t = quant_embed[j, label_i[j] - out_vocab.base_quant]\n",
    "            while pnode and pnode.right is node:\n",
    "                t = decoder.merge_subtree(pnode.op, pnode.tl, t)\n",
    "                node, pnode = pnode, pnode.up \n",
    "            if pnode is None: \n",
    "                continue\n",
    "            pnode.tl = t\n",
    "            ql_tl.append(torch.cat([pnode.ql, pnode.tl]))\n",
    "            nodes[j] = pnode.right = Node(pnode)\n",
    "            is_right[j] = True\n",
    "\n",
    "        qp = torch.zeros((n_batch, n_hid), device=device)\n",
    "        qp[is_left] = qleft_qp\n",
    "        if ql_tl:\n",
    "            qp[is_right] = decoder.gts_right(torch.stack(ql_tl))\n",
    "\n",
    "    label = label.to(device).view(-1)\n",
    "    scores = torch.stack(scores, dim=1).view(-1, out_vocab.n_ops + n_quant)\n",
    "    loss = F.cross_entropy(scores, label, ignore_index=out_vocab.pad)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    return loss.item()\n",
    "\n",
    "def flag(batch, model, opt, M, alpha):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pert = torch.FloatTensor(*batch.shape).uniform_(-alpha, alpha)\n",
    "    pert.requires_grad_()\n",
    "    loss = train(batch, model, opt) / M\n",
    "    \n",
    "    for _ in range(M-1):\n",
    "        loss.backward()\n",
    "        pert_data = pert.detach() + alpha*torch.sign(pert.grad.detach())\n",
    "        pert.data = pert_data.data\n",
    "        pert.grad[:] = 0\n",
    "        loss = train(batch, model, opt) / M\n",
    "      \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6T-OymutSo2"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Vh3tKN1tSo2"
   },
   "outputs": [],
   "source": [
    "class BeamNode(Node):\n",
    "    def __init__(self, up, prev, qp, token=None):\n",
    "        super().__init__(up)\n",
    "        self.prev = prev\n",
    "        self.qp = qp\n",
    "        self.token = token\n",
    "\n",
    "    def trace_tokens(self, *last_token):\n",
    "        if self.prev is None:\n",
    "            return list(last_token)\n",
    "        tokens = self.prev.trace_tokens()\n",
    "        tokens.append(self.token)\n",
    "        tokens.extend(last_token)\n",
    "        return tokens\n",
    "\n",
    "def predict(d, model, beam_size=5, n_max_out=45):\n",
    "    in_idxs = d['in_idxs'].unsqueeze(0).to(device=device)\n",
    "    n_nodes = len(d['in_tokens'])\n",
    "    qcomp_graph = dgl.graph(get_quantity_comparison_edges(d), num_nodes=n_nodes).to(device)\n",
    "    qcell_graph = dgl.graph(get_quantity_cell_edges(d), num_nodes=n_nodes).to(device)\n",
    "\n",
    "    zbar, qroot = model.encode(in_idxs, [d['n_in']], qcomp_graph, qcell_graph)\n",
    "    z_nP = zbar[:, d['nP_positions']]\n",
    "\n",
    "    decoder = model.decoder\n",
    "\n",
    "    quant_embed = torch.cat([decoder.constant_embedding, z_nP], dim=1)\n",
    "    op_min, op_max = out_vocab.base_op, out_vocab.base_op + out_vocab.n_ops\n",
    "\n",
    "    best_done_beam = (-np.inf, None, None)\n",
    "    beams = [(0, BeamNode(up=None, prev=None, qp=decoder.qp_gate(qroot)))]\n",
    "    for _ in range(n_max_out):\n",
    "        new_beams = []\n",
    "        for logp_prev, node in beams:\n",
    "            Gc = decoder.gts_attention(node.qp, zbar)\n",
    "            qp_Gc = torch.cat([node.qp, Gc], dim=1)\n",
    "\n",
    "            log_prob = decoder.gts_predict(qp_Gc, quant_embed).log_softmax(dim=1)\n",
    "            top_logps, top_tokens = log_prob.topk(beam_size, dim=1)\n",
    "            for logp_token_, out_token_ in zip(top_logps.unbind(dim=1), top_tokens.unbind(dim=1)):\n",
    "                out_token = out_token_.item()\n",
    "                logp = logp_prev + logp_token_.item()\n",
    "                if op_min <= out_token < op_max:\n",
    "                    op_embed = decoder.op_embedding(out_token_)\n",
    "                    qp_Gc_op = torch.cat([qp_Gc, op_embed], dim=1)\n",
    "                    prev_node = copy(node)\n",
    "                    next_node = prev_node.left = BeamNode(\n",
    "                        up=prev_node, prev=prev_node,\n",
    "                        qp=decoder.gts_left_qp(qp_Gc_op),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                    prev_node.op = op_embed\n",
    "                    prev_node.ql = decoder.gts_left(qp_Gc_op)\n",
    "                else:\n",
    "                    pnode, prev_node = node.up, node\n",
    "                    t = quant_embed[:, out_token - out_vocab.base_quant]\n",
    "                    while pnode and pnode.tl is not None:\n",
    "                        t = decoder.merge_subtree(pnode.op, pnode.tl, t)\n",
    "                        node, pnode = pnode, pnode.up\n",
    "                    if pnode is None:\n",
    "                        best_done_beam = max(best_done_beam, (logp, prev_node, out_token))\n",
    "                        continue\n",
    "                    pnode = copy(pnode)\n",
    "                    pnode.tl = t\n",
    "                    next_node = pnode.right = BeamNode(\n",
    "                        up=pnode, prev=prev_node,\n",
    "                        qp=decoder.gts_right(torch.cat([pnode.ql, pnode.tl], dim=1)),\n",
    "                        token=out_token\n",
    "                    )\n",
    "                new_beams.append((logp, next_node))\n",
    "        beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "        done_logp, done_node, done_last_token = best_done_beam\n",
    "        if not len(beams) or done_logp >= beams[0][0]:\n",
    "            break\n",
    "    return done_node.trace_tokens(done_last_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaVKX9NGtSo5"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to generate the t5 model and datasets\n",
    "import pickle\n",
    "import transformers\n",
    "\n",
    "with open('t5-math-data.pickle', 'rb') as pick:\n",
    "        dataset = pickle.load(pick)\n",
    "        \n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 512\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "class CreateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, max_tokens):\n",
    "        self.data = data\n",
    "        self.max_tokens = max_tokens\n",
    "\n",
    "    def __len__(self):\n",
    "        return MAXLEN\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        question = self.data[item]['input_ids_list']\n",
    "        answer = self.data[item]['label_ids_list']\n",
    "        nP = self.data[item]['nP']\n",
    "        nP_locs = self.data[item]['nP_positions']\n",
    "\n",
    "        question = question[:self.max_tokens]\n",
    "        answer = answer[:self.max_tokens]\n",
    "\n",
    "        ## Make sure the answer has the same length for each\n",
    "        num_to_pad = self.max_tokens - len(answer)\n",
    "        answer = F.pad(torch.Tensor(answer), [0, num_to_pad], mode='constant', value=-100)\n",
    "        \n",
    "        # Make sure the answer has the same length for each\n",
    "        num_to_pad = self.max_tokens - len(nP)\n",
    "        nP = F.pad(torch.Tensor(nP), [0, num_to_pad], mode='constant', value=-100)\n",
    "        nP_locs = F.pad(torch.LongTensor(nP_locs), [0, num_to_pad], mode='constant', value=-100)\n",
    "        nP_locs_mask = torch.zeros(self.max_tokens)\n",
    "        nP_locs_mask[self.data[item]['nP_positions']] = 1\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        return{\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'nP': nP,\n",
    "            'nP_positions': nP_locs,\n",
    "            'nP_in_mask': nP_locs_mask\n",
    "        }\n",
    "\n",
    "def create_data_loader(dataset):\n",
    "    ds = CreateDataset(dataset, MAXLEN)\n",
    "\n",
    "    return torch.utils.data.DataLoader(ds, batch_size=BATCH_SIZE, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(dataset)\n",
    "\n",
    "check_data = next(iter(train_data_loader))\n",
    "print(check_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the vocab from the t5 tokenizer \n",
    "tokenizer = transformers.T5Tokenizer.from_pretrained('t5-large')\n",
    "in_vocab = tokenizer.save_vocabulary('./')\n",
    "out_vocab = tokenizer.save_vocabulary('./')\n",
    "\n",
    "print(in_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup the t5 model \n",
    "t5_model = transformers.T5Model.from_pretrained('t5-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkWDuTt6-s9W"
   },
   "outputs": [],
   "source": [
    "hyp_use_t5 = None\n",
    "hyp_n_max_in = 100\n",
    "hyp_n_epochs = 100\n",
    "hyp_n_batch = 64\n",
    "hyp_lr = 1e-3\n",
    "hyp_n_layers = 3\n",
    "hyp_n_hid = 512\n",
    "hyp_kv = 64\n",
    "hyp_n_head = 8\n",
    "hyp_wd = 0\n",
    "hyp_t5_freeze_layers = []\n",
    "hyp_t5_decay = 1e-5\n",
    "hyp_eval_epoch = 30\n",
    "\n",
    "use_t5 = hyp_use_t5\n",
    "model_save_dir = f'./models/{use_t5 or \"custom\"}'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "n_max_in = hyp_n_max_in #100\n",
    "n_epochs = hyp_n_epochs #100\n",
    "n_batch = hyp_n_batch #64\n",
    "learning_rate = hyp_lr #1e-3\n",
    "if use_t5:\n",
    "    freeze_layers = hyp_t5_freeze_layers #[]\n",
    "    weight_decay = hyp_t5_decay #1e-5\n",
    "    n_hid = dict(small=512, base=768)[use_t5]\n",
    "else:\n",
    "    n_layers = hyp_n_layers #3\n",
    "    n_hid = hyp_n_hid #512\n",
    "    n_k = n_v = hyp_kv #64\n",
    "    n_head = hyp_n_head #8\n",
    "    weight_decay = hyp_wd #0\n",
    "device = 'cuda:0'\n",
    "\n",
    "# train_data, val_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5)\n",
    "train_data = train_data_loader \n",
    "val_data = train_data_loader \n",
    "n_max_nP = 10\n",
    "\n",
    "\n",
    "\n",
    "tensorize_data(itertools.chain(train_data, val_data))\n",
    "\n",
    "model = Model()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "model.to(device)\n",
    "\n",
    "epoch = 0\n",
    "while epoch < n_epochs:\n",
    "    print('Epoch:', epoch + 1)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for start in trange(0, len(train_data), n_batch):\n",
    "        batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "        loss = train(batch, model, opt)\n",
    "        losses.append(loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training loss: {np.mean(losses):.3g}')\n",
    "\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        value_match, equation_match = [], []\n",
    "        with torch.no_grad():\n",
    "            for d in tqdm(val_data):\n",
    "                if d['is_quadratic']:\n",
    "                    val_match = eq_match = False\n",
    "                else:\n",
    "                    pred = predict(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                value_match.append(val_match)\n",
    "                equation_match.append(eq_match)\n",
    "        print(f'Validation expression accuracy: {np.mean(equation_match):.3g}')\n",
    "        print(f'Validation value accuracy: {np.mean(value_match):.3g}')\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, f'model-{epoch}.pth'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxtnA6nZ8LZn"
   },
   "source": [
    "# CUSTOM TRANSFORMER BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtB-KQ0PtSo5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hyp_use_t5 = \"small\"\n",
    "hyp_n_max_in = 100\n",
    "hyp_n_epochs = 100\n",
    "hyp_n_batch = 64\n",
    "hyp_lr = 1e-3\n",
    "hyp_n_layers = 3\n",
    "hyp_n_hid = 512\n",
    "hyp_kv = 64\n",
    "hyp_n_head = 8\n",
    "hyp_wd = 0\n",
    "hyp_t5_freeze_layers = []\n",
    "hyp_t5_decay = 1e-5\n",
    "hyp_eval_epoch = 30\n",
    "\n",
    "use_t5 = hyp_use_t5\n",
    "model_save_dir = f'./models/{use_t5 or \"custom\"}'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "n_max_in = hyp_n_max_in #100\n",
    "n_epochs = hyp_n_epochs #100\n",
    "n_batch = hyp_n_batch #64\n",
    "learning_rate = hyp_lr #1e-3\n",
    "if use_t5:\n",
    "    freeze_layers = hyp_t5_freeze_layers #[]\n",
    "    weight_decay = hyp_t5_decay #1e-5\n",
    "    n_hid = dict(small=512, base=768)[use_t5]\n",
    "else:\n",
    "    n_layers = hyp_n_layers #3\n",
    "    n_hid = hyp_n_hid #512\n",
    "    n_k = n_v = hyp_kv #64\n",
    "    n_head = hyp_n_head #8\n",
    "    weight_decay = hyp_wd #0\n",
    "device = 'cuda:0'\n",
    "\n",
    "train_data, val_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5)\n",
    "tensorize_data(itertools.chain(train_data, val_data))\n",
    "\n",
    "model = Model()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "model.to(device)\n",
    "\n",
    "epoch = 0\n",
    "while epoch < n_epochs:\n",
    "    print('Epoch:', epoch + 1)\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for start in trange(0, len(train_data), n_batch):\n",
    "        batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "        loss = train(batch, model, opt)\n",
    "        losses.append(loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training loss: {np.mean(losses):.3g}')\n",
    "\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        value_match, equation_match = [], []\n",
    "        with torch.no_grad():\n",
    "            for d in tqdm(val_data):\n",
    "                if d['is_quadratic']:\n",
    "                    val_match = eq_match = False\n",
    "                else:\n",
    "                    pred = predict(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                value_match.append(val_match)\n",
    "                equation_match.append(eq_match)\n",
    "        print(f'Validation expression accuracy: {np.mean(equation_match):.3g}')\n",
    "        print(f'Validation value accuracy: {np.mean(value_match):.3g}')\n",
    "        torch.save(model.state_dict(), os.path.join(model_save_dir, f'model-{epoch}.pth'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E46XsaY881b1"
   },
   "source": [
    "# T5 SMALL BENCHMARK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UqazdOmX17I"
   },
   "outputs": [],
   "source": [
    "hyp_search_custom_results = {}\n",
    "hyp_search_custom_conf = [\n",
    "    (\"batch\", 64),\n",
    "    (\"batch\", 32),\n",
    "    (\"batch\", 128),\n",
    "    (\"lr\", 0.005),\n",
    "    (\"lr\", 0.0002),\n",
    "    (\"n_l\", 5),\n",
    "    (\"n_l\", 7),\n",
    "    (\"n_hid\", 1024),\n",
    "    (\"kv\", 128),\n",
    "    (\"head\", 4),\n",
    "    (\"head\", 16),\n",
    "]\n",
    "\n",
    "for hyp, val in hyp_search_custom_conf:\n",
    "\n",
    "    hyp_use_t5 = None\n",
    "    hyp_n_max_in = 100\n",
    "    hyp_n_epochs = 100\n",
    "    hyp_n_batch = 64\n",
    "    hyp_lr = 1e-3\n",
    "    hyp_n_layers = 3\n",
    "    hyp_n_hid = 512\n",
    "    hyp_kv = 64\n",
    "    hyp_n_head = 8\n",
    "    hyp_wd = 0\n",
    "    hyp_t5_freeze_layers = []\n",
    "    hyp_t5_decay = 1e-5\n",
    "    hyp_eval_epoch = 30\n",
    "\n",
    "    if hyp == \"batch\":\n",
    "        hyp_n_batch = val\n",
    "    elif hyp == \"lr\":\n",
    "        hyp_lr = val\n",
    "    elif hyp == \"n_l\":\n",
    "        hyp_n_layers = val\n",
    "    elif hyp == \"n_hid\":\n",
    "        hyp_n_hid = val\n",
    "    elif hyp == \"kv\":\n",
    "        hyp_kv = val\n",
    "    elif hyp == \"head\":\n",
    "        hyp_n_head = val\n",
    "\n",
    "    if hyp not in hyp_search_custom_results:\n",
    "        hyp_search_custom_results[hyp] = {}\n",
    "    hyp_search_custom_results[hyp][val] = []\n",
    "\n",
    "    use_t5 = hyp_use_t5\n",
    "    model_save_dir = f'./models/{use_t5 or \"custom\"}'\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    n_max_in = hyp_n_max_in #100\n",
    "    n_epochs = hyp_n_epochs #100\n",
    "    n_batch = hyp_n_batch #64\n",
    "    learning_rate = hyp_lr #1e-3\n",
    "    if use_t5:\n",
    "        freeze_layers = hyp_t5_freeze_layers #[]\n",
    "        weight_decay = hyp_t5_decay #1e-5\n",
    "        n_hid = dict(small=512, base=768)[use_t5]\n",
    "    else:\n",
    "        n_layers = hyp_n_layers #3\n",
    "        n_hid = hyp_n_hid #512\n",
    "        n_k = n_v = hyp_kv #64\n",
    "        n_head = hyp_n_head #8\n",
    "        weight_decay = hyp_wd #0\n",
    "    device = 'cuda:0'\n",
    "\n",
    "    #train_data, val_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5)\n",
    "    tensorize_data(itertools.chain(train_data, val_data))\n",
    "\n",
    "    model = Model()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "    model.to(device)\n",
    "\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        print('Epoch:', epoch + 1)\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for start in trange(0, len(train_data), n_batch):\n",
    "            batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "            loss = train(batch, model, opt)\n",
    "            losses.append(loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'Training loss: {np.mean(losses):.3g}')\n",
    "\n",
    "        epoch += 1\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            value_match, equation_match = [], []\n",
    "            with torch.no_grad():\n",
    "                for d in tqdm(val_data):\n",
    "                    if d['is_quadratic']:\n",
    "                        val_match = eq_match = False\n",
    "                    else:\n",
    "                        pred = predict(d, model)\n",
    "                        d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                        val_match, eq_match = check_match(pred, d)\n",
    "                    value_match.append(val_match)\n",
    "                    equation_match.append(eq_match)\n",
    "            print(f'Validation expression accuracy: {np.mean(equation_match):.3g}')\n",
    "            print(f'Validation value accuracy: {np.mean(value_match):.3g}')\n",
    "\n",
    "            hyp_search_custom_results[hyp][val].append((np.mean(equation_match), np.mean(value_match)))\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_dir, f'model-{epoch}.pth'))\n",
    "        print()\n",
    "\n",
    "print()\n",
    "print(hyp_search_custom_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIbcj5VA9Ajw"
   },
   "source": [
    "Custom Transformer Hyperparameters\n",
    "\n",
    "| Batch Size | Learning Rate | Num Layers | Num Hidden | kv dim | Num Head | Val Expression Acc | Val Value Acc |\n",
    "| --- | --- | --- | --- | --- | --- |  --- | --- |\n",
    "| 64 | 0.001 | 3 | 512 | 64 | 8 | 0.742 | 0.765 |\n",
    "| 32 | 0.001 | 3 | 512 | 64 | 8 | 0.000 | 0.023 |\n",
    "| 128 | 0.001 | 3 | 512 | 64 | 8 | 0.742 | 0.770 |\n",
    "| 64 | 0.005 | 3 | 512 | 64 | 8 | 0.000 | 0.019 |\n",
    "| 64 | 0.0002 | 3 | 512 | 64 | 8 | 0.732 | 0.746 |\n",
    "| 64 | 0.001 | 5 | 512 | 64 | 8 | 0.709 | 0.723 |\n",
    "| 64 | 0.001 | 7 | 512 | 64 | 8 | 0.540 | 0.545 |\n",
    "| 64 | 0.001 | 3 | 1024 | 64 | 8 | 0.000 | 0.014 |\n",
    "| 64 | 0.001 | 3 | 512 | 128 | 8 | 0.751 | 0.775 |\n",
    "| 64 | 0.001 | 3 | 512 | 64 | 4 | 0.761 | 0.779 |\n",
    "| 64 | 0.001 | 3 | 512 | 64 | 16 | 0.714 | 0.732 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wB5h-nVRrJgE"
   },
   "outputs": [],
   "source": [
    "hyp_search_t5_results = {}\n",
    "hyp_search_t5_conf = [\n",
    "    (\"freeze\", [0, 1, 2, 3, 4, 5]),\n",
    "    (\"freeze\", [0, 1, 2, 3]),\n",
    "    (\"freeze\", [0, 1]),\n",
    "    (\"decay\", 1e-6),\n",
    "    (\"decay\", 1e-4),\n",
    "]\n",
    "\n",
    "for hyp, val in hyp_search_t5_conf:\n",
    "\n",
    "    hyp_use_t5 = \"small\"\n",
    "    hyp_n_max_in = 100\n",
    "    hyp_n_epochs = 100\n",
    "    hyp_n_batch = 64\n",
    "    hyp_lr = 1e-3\n",
    "    hyp_n_layers = 3\n",
    "    hyp_n_hid = 512\n",
    "    hyp_kv = 64\n",
    "    hyp_n_head = 8\n",
    "    hyp_wd = 0\n",
    "    hyp_t5_freeze_layers = []\n",
    "    hyp_t5_decay = 1e-5\n",
    "    hyp_eval_epoch = 30\n",
    "\n",
    "    if hyp == \"batch\":\n",
    "        hyp_n_batch = val\n",
    "    elif hyp == \"lr\":\n",
    "        hyp_lr = val\n",
    "    elif hyp == \"freeze\":\n",
    "        hyp_t5_freeze_layers = val\n",
    "    elif hyp == \"decay\":\n",
    "        hyp_t5_decay = val\n",
    "\n",
    "    if hyp not in hyp_search_t5_results:\n",
    "        hyp_search_t5_results[hyp] = {}\n",
    "    hyp_search_t5_results[hyp][str(val)] = []\n",
    "\n",
    "    use_t5 = hyp_use_t5\n",
    "    model_save_dir = f'./models/{use_t5 or \"custom\"}'\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "    n_max_in = hyp_n_max_in #100\n",
    "    n_epochs = hyp_n_epochs #100\n",
    "    n_batch = hyp_n_batch #64\n",
    "    learning_rate = hyp_lr #1e-3\n",
    "    if use_t5:\n",
    "        freeze_layers = hyp_t5_freeze_layers #[]\n",
    "        weight_decay = hyp_t5_decay #1e-5\n",
    "        n_hid = dict(small=512, base=768)[use_t5]\n",
    "    else:\n",
    "        n_layers = hyp_n_layers #3\n",
    "        n_hid = hyp_n_hid #512\n",
    "        n_k = n_v = hyp_kv #64\n",
    "        n_head = hyp_n_head #8\n",
    "        weight_decay = hyp_wd #0\n",
    "    device = 'cuda:0'\n",
    "\n",
    "    train_data, val_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5)\n",
    "    tensorize_data(itertools.chain(train_data, val_data))\n",
    "\n",
    "    model = Model()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "    model.to(device)\n",
    "\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        print('Epoch:', epoch + 1)\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for start in trange(0, len(train_data), n_batch):\n",
    "            batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "            loss = train(batch, model, opt)\n",
    "            losses.append(loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'Training loss: {np.mean(losses):.3g}')\n",
    "\n",
    "        epoch += 1\n",
    "        if epoch % 10 == 0:\n",
    "            model.eval()\n",
    "            value_match, equation_match = [], []\n",
    "            with torch.no_grad():\n",
    "                for d in tqdm(val_data):\n",
    "                    if d['is_quadratic']:\n",
    "                        val_match = eq_match = False\n",
    "                    else:\n",
    "                        pred = predict(d, model)\n",
    "                        d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                        val_match, eq_match = check_match(pred, d)\n",
    "                    value_match.append(val_match)\n",
    "                    equation_match.append(eq_match)\n",
    "            print(f'Validation expression accuracy: {np.mean(equation_match):.3g}')\n",
    "            print(f'Validation value accuracy: {np.mean(value_match):.3g}')\n",
    "\n",
    "            hyp_search_t5_results[hyp][str(val)].append((np.mean(equation_match), np.mean(value_match)))\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_dir, f'model-{epoch}.pth'))\n",
    "        print()\n",
    "\n",
    "print()\n",
    "print(hyp_search_t5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qHBYns1BJBc"
   },
   "source": [
    "T5 Hyperparameters\n",
    "\n",
    "| Batch Size | Freeze Layers | Weight Decay | Val Expression Acc | Val Value Acc |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 64 | [] | 1e-5 | 0.709 | 0.728 |\n",
    "| 128 | [] | 1e-5 | 0.709 | 0.728 |\n",
    "| 64 | [0, 1] | 1e-5 | 0.723 | 0.742 |\n",
    "| 64 | [0, 1, 2, 3] | 1e-5 | 0.685 | 0.704 |\n",
    "| 64 | [0, 1, 2, 3, 4, 5] | 1e-5 | 0.648 | 0.671 |\n",
    "| 64 | [] | 1e-6 | 0.718 | 0.737 |\n",
    "| 64 | [] | 1e-4 | 0.737 | 0.761 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSPMuNuNtSo8"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFUEeAqqerSw"
   },
   "outputs": [],
   "source": [
    "hyp_use_t5 = \"base\"\n",
    "hyp_n_max_in = 100\n",
    "hyp_n_epochs = 120\n",
    "hyp_n_batch = 64\n",
    "hyp_lr = 0.0005\n",
    "hyp_t5_freeze_layers = []\n",
    "hyp_t5_decay = 0.000001 #0.0001\n",
    "hyp_eval_epoch = 100\n",
    "\n",
    "use_t5 = hyp_use_t5\n",
    "model_save_dir = f'./models/{use_t5 or \"custom\"}'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "n_max_in = hyp_n_max_in #100\n",
    "n_epochs = hyp_n_epochs #100\n",
    "n_batch = hyp_n_batch #64\n",
    "learning_rate = hyp_lr #1e-3\n",
    "if use_t5:\n",
    "    freeze_layers = hyp_t5_freeze_layers #[]\n",
    "    weight_decay = hyp_t5_decay #1e-5\n",
    "    n_hid = dict(small=512, base=768)[use_t5]\n",
    "else:\n",
    "    n_layers = hyp_n_layers #3\n",
    "    n_hid = hyp_n_hid #512\n",
    "    n_k = n_v = hyp_kv #64\n",
    "    n_head = hyp_n_head #8\n",
    "    weight_decay = hyp_wd #0\n",
    "device = 'cuda:0'\n",
    "\n",
    "train_data, val_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5)\n",
    "tensorize_data(itertools.chain(train_data, val_data))\n",
    "\n",
    "model = Model()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs)\n",
    "model.to(device)\n",
    "\n",
    "epoch = 0\n",
    "while epoch < n_epochs:\n",
    "    print('Epoch:', epoch + 1)\n",
    "    model.train()\n",
    "  \n",
    "    losses = []\n",
    "    for start in trange(0, len(train_data), n_batch):\n",
    "        batch = sorted(train_data[start: start + n_batch], key=lambda d: -d['n_in'])\n",
    "        loss = train(batch, model, opt)\n",
    "        losses.append(loss)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Training loss: {np.mean(losses):.3g}')\n",
    "\n",
    "    epoch += 1\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        value_match, equation_match = [], []\n",
    "        with torch.no_grad():\n",
    "            for d in tqdm(val_data):\n",
    "                if d['is_quadratic']:\n",
    "                    val_match = eq_match = False\n",
    "                else:\n",
    "                    pred = predict(d, model)\n",
    "                    d['pred_tokens'] = [out_vocab.idx2token[idx] for idx in pred]\n",
    "                    val_match, eq_match = check_match(pred, d)\n",
    "                value_match.append(val_match)\n",
    "                equation_match.append(eq_match)\n",
    "        print(f'Validation expression accuracy: {np.mean(equation_match):.3g}')\n",
    "        print(f'Validation value accuracy: {np.mean(value_match):.3g}')\n",
    "        if (np.mean(value_match) > 0.78):\n",
    "            torch.save(model.state_dict(), os.path.join(model_save_dir, f'model-{epoch}.pth'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVpE1FSUtSo8"
   },
   "outputs": [],
   "source": [
    "use_t5 = hyp_use_t5\n",
    "eval_epoch = 120\n",
    "device = 'cuda:0' #'cpu'\n",
    "\n",
    "n_max_in = hyp_n_max_in #100\n",
    "if use_t5:\n",
    "    freeze_layers = hyp_t5_freeze_layers #[]\n",
    "    n_hid = dict(small=512, base=768)[use_t5]\n",
    "else:\n",
    "    n_layers = hyp_n_layers #3\n",
    "    n_hid = hyp_n_hid #512\n",
    "    n_k = n_v = hyp_kv #64\n",
    "    n_head = hyp_n_head #8\n",
    "\n",
    "test_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5, do_eval=True)\n",
    "model = Model().to(device)\n",
    "model.load_state_dict(torch.load(f'./models/{use_t5 or \"custom\"}/model-{eval_epoch}.pth'))\n",
    "tensorize_data(test_data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for d in tqdm(test_data):\n",
    "        pred = predict(d, model)\n",
    "        d['pred_tokens'] = pred_tokens = [out_vocab.idx2token[idx] for idx in pred]\n",
    "        d['subbed_tokens'] = subbed_tokens = sub_nP(pred_tokens, d['nP'])\n",
    "        d['Predicted'] = round(evaluate_prefix_expression(subbed_tokens), 3)\n",
    "\n",
    "import pandas as pd\n",
    "predictions = pd.DataFrame(test_data).set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsuROmXhtSo-"
   },
   "outputs": [],
   "source": [
    "predictions[['pred_tokens', 'subbed_tokens', 'Predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqZ3WOH1tSpA"
   },
   "outputs": [],
   "source": [
    "predictions[['Predicted']].replace([np.inf, -np.inf, np.nan], 0).to_csv('./preds/prediction_{}.csv'.format(eval_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKboNXcb35K8"
   },
   "outputs": [],
   "source": [
    "\n",
    "modelfps = [\n",
    "]\n",
    "predictions_list = []\n",
    "for modelfp in modelfps:\n",
    "    use_t5 = \"base\"\n",
    "    device = 'cuda:0' #'cpu'\n",
    "    n_max_in = 100\n",
    "    if use_t5:\n",
    "        freeze_layers = []\n",
    "        n_hid = dict(small=512, base=768)[use_t5]\n",
    "    else:\n",
    "        n_layers = hyp_n_layers #3\n",
    "        n_hid = hyp_n_hid #512\n",
    "        n_k = n_v = hyp_kv #64\n",
    "        n_head = hyp_n_head #8\n",
    "\n",
    "    test_data, in_vocab, out_vocab, n_max_nP, t5_model = setup(use_t5, do_eval=True)\n",
    "    model = Model().to(device)\n",
    "    model.load_state_dict(torch.load(modelfp))\n",
    "    tensorize_data(test_data)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(test_data):\n",
    "            pred = predict(d, model)\n",
    "            d['pred_tokens'] = pred_tokens = [out_vocab.idx2token[idx] for idx in pred]\n",
    "            d['subbed_tokens'] = subbed_tokens = sub_nP(pred_tokens, d['nP'])\n",
    "            d['Predicted'] = round(evaluate_prefix_expression(subbed_tokens), 3)\n",
    "\n",
    "    import pandas as pd\n",
    "    predictions = pd.DataFrame(test_data).set_index('Id')\n",
    "    predictions_list.append(predictions)\n",
    "\n",
    "print(predictions_list)\n",
    "\n",
    "prediction_merged = predictions_list[0]\n",
    "for index, row in prediction_merged.iterrows():\n",
    "    i_res = []\n",
    "    for preddf in predictions_list:\n",
    "        p_row = preddf.iloc[index]\n",
    "        match = False\n",
    "        for r in i_res:\n",
    "            if ((p_row['pred_tokens'] == r[0]) and (p_row['subbed_tokens'] == r[1]) and (p_row['Predicted'] == r[2])):\n",
    "                match = True\n",
    "                r[3] += 1\n",
    "        if not match:\n",
    "            i_res.append((p_row['pred_tokens'], p_row['subbed_tokens'], p_row['Predicted'], 1))\n",
    "\n",
    "    max_v, max_i = 0, -1\n",
    "    for ir in range(len(i_res)):\n",
    "        if i_res[ir][3] > max_v:\n",
    "            max_v = i_res[ir][3]\n",
    "            max_i = ir\n",
    "    row['pred_tokens'] = i_res[max_i]['pred_tokens']\n",
    "    row['subbed_tokens'] = i_res[max_i]['subbed_tokens']\n",
    "    row['Predicted'] = i_res[max_i]['Predicted']\n",
    "\n",
    "print(prediction_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgISWmnrCS5z"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "graph2tree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
